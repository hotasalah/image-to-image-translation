# Leveraging the Pix2Pix GAN
In Image-to-Image Translation, the task is to translate images from one domain to another by learning a mapping between the input and output images, using a training dataset of aligned or unaligned cross-domain image pairs. The focus in this project is on Paired Image-to-Image Translation.
<br> The objective is to transform edges and hand drawings of pbjects into meaningful images.
<br> The input image that is passed to the networl contains patches of color that are present in randomly chosen regions. This way, the user is capable to take a hand-drawn contour image, sprinkle the required colors at different parts of the image, and generate a new image.

![demo](https://github.com/hotasalah/image-to-image-translation/blob/main/demo_pix2pix_img_1.png)
![demo](https://github.com/hotasalah/image-to-image-translation/blob/main/demo_pix2pix_img_2.png)
![demo](https://github.com/hotasalah/image-to-image-translation/blob/main/demo_pix2pix_img_3.png)
